{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import time\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import types \n",
    "from pyspark.sql.functions import isnan, when, count, col, round \n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:\\Freelancing\\Exact\\yellow_tripdata_2020-01.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# Load data into Spark DataFrame\n",
    "trips_df = spark.read \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .csv(\"D:\\Freelancing\\Exact\\yellow_tripdata_2020-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.registerTempTable(\"trips\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinctDF = trips_df.distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_filtered_Total_Fare count: 6232809\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "customSchema = StructType([\n",
    "        StructField(\"VendorID\", ShortType(), True),\n",
    "        StructField(\"tpep_pickup_datetime\", TimestampType(), True),\n",
    "        StructField(\"tpep_dropoff_datetime\", TimestampType(), True),\n",
    "        StructField(\"passenger_count\", ShortType(), True),\n",
    "        StructField(\"trip_distance\", DecimalType(), True),\n",
    "        StructField(\"RatecodeID\", ShortType(), True),\n",
    "        StructField(\"store_and_fwd_flag\", BooleanType(), True),\n",
    "        StructField(\"PULocationID\", ShortType(), True),\n",
    "        StructField(\"DOLocationID\", ShortType(), True),\n",
    "        StructField(\"payment_type\", ShortType(), True),\n",
    "        StructField(\"fare_amount\", DecimalType(), True),   \n",
    "        StructField(\"extra\", DecimalType(), True),\n",
    "        StructField(\"mta_tax\", DecimalType(), True),\n",
    "        StructField(\"tip_amount\", DecimalType(), True),\n",
    "        StructField(\"tolls_amount\", DecimalType(), True),\n",
    "        StructField(\"improvement_surcharge\", DecimalType(), True),\n",
    "        StructField(\"total_amount\", DecimalType(), True),\n",
    "        StructField(\"congestion_surcharge\", DecimalType(), True),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "root\n",
    " |-- VendorID: integer (nullable = true)\n",
    " |-- tpep_pickup_datetime: string (nullable = true)\n",
    " |-- tpep_dropoff_datetime: string (nullable = true)\n",
    " |-- passenger_count: integer (nullable = true)\n",
    " |-- trip_distance: double (nullable = true)\n",
    " |-- RatecodeID: integer (nullable = true)\n",
    " |-- store_and_fwd_flag: string (nullable = true)\n",
    " |-- PULocationID: integer (nullable = true)\n",
    " |-- DOLocationID: integer (nullable = true)\n",
    " |-- payment_type: integer (nullable = true)\n",
    " |-- fare_amount: double (nullable = true)\n",
    " |-- extra: double (nullable = true)\n",
    " |-- mta_tax: double (nullable = true)\n",
    " |-- tip_amount: double (nullable = true)\n",
    " |-- tolls_amount: double (nullable = true)\n",
    " |-- improvement_surcharge: double (nullable = true)\n",
    " |-- total_amount: double (nullable = true)\n",
    " |-- congestion_surcharge: double (nullable = true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: short (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: short (nullable = true)\n",
      " |-- trip_distance: decimal(10,0) (nullable = true)\n",
      " |-- RatecodeID: short (nullable = true)\n",
      " |-- store_and_fwd_flag: decimal(10,0) (nullable = true)\n",
      " |-- PULocationID: short (nullable = true)\n",
      " |-- DOLocationID: short (nullable = true)\n",
      " |-- payment_type: short (nullable = true)\n",
      " |-- fare_amount: decimal(10,0) (nullable = true)\n",
      " |-- extra: decimal(10,0) (nullable = true)\n",
      " |-- mta_tax: decimal(10,0) (nullable = true)\n",
      " |-- tip_amount: decimal(10,0) (nullable = true)\n",
      " |-- tolls_amount: decimal(10,0) (nullable = true)\n",
      " |-- improvement_surcharge: decimal(10,0) (nullable = true)\n",
      " |-- total_amount: decimal(10,0) (nullable = true)\n",
      " |-- congestion_surcharge: decimal(10,0) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.schema(customSchema).parquet('trip_data_01 copy.parquet')\n",
    "df_parquet = spark.read.parquet('trip_data_01 copy.parquet')\n",
    "\n",
    "df_parquet = df_parquet.select(\n",
    "    col('VendorID').cast(ShortType()),\n",
    "    col('tpep_pickup_datetime').cast(TimestampType()),\n",
    "    col('tpep_dropoff_datetime').cast(TimestampType()),\n",
    "    col('passenger_count').cast(ShortType()),\n",
    "    col('trip_distance').cast(DecimalType()),\n",
    "    col('RatecodeID').cast(ShortType()),\n",
    "    col('store_and_fwd_flag').cast(DecimalType()),\n",
    "    col('PULocationID').cast(ShortType()),\n",
    "    col('DOLocationID').cast(ShortType()),\n",
    "    col('payment_type').cast(ShortType()),\n",
    "    col('fare_amount').cast(DecimalType()),\n",
    "    col('extra').cast(DecimalType()),\n",
    "    col('mta_tax').cast(DecimalType()),\n",
    "    col('tip_amount').cast(DecimalType()),\n",
    "    col('tolls_amount').cast(DecimalType()),\n",
    "    col('improvement_surcharge').cast(DecimalType()),\n",
    "    col('total_amount').cast(DecimalType()),\n",
    "    col('congestion_surcharge').cast(DecimalType()),\n",
    "    \n",
    ")\n",
    "\n",
    "df_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----------------------+\n",
      "|Quarter|DROPOff_Location_ID|AVERAGE_TIP_Percentage|\n",
      "+-------+-------------------+----------------------+\n",
      "|      1|                265|                 13.37|\n",
      "|      2|                246|                 22.73|\n",
      "|      3|                263|                 22.22|\n",
      "|      4|                265|                 20.00|\n",
      "+-------+-------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parquet.createOrReplaceTempView(\"parquetTable\")\n",
    "spark.sql(\"SELECT b as Quarter , MAX(d) as DROPOff_Location_ID, CAST(MAX(a)*100 as Numeric(4,2) ) as AVERAGE_TIP_Percentage  from (SELECT DOLocationID as d, QUARTER(tpep_dropoff_datetime) as b ,AVG(tip_amount/total_amount) as a  FROM parquetTable GROUP BY  d, b ORDER BY a DESC) GROUP BY b ORDER BY b ASC ;\") .show()\n",
    "#b is the QUARTER\n",
    "#d is the Location_ID\n",
    "#a is the Average Percentage Amount Calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+---+\n",
      "|month(CAST(tpep_pickup_datetime AS DATE))|  a|\n",
      "+-----------------------------------------+---+\n",
      "|                                       12|  4|\n",
      "|                                        7|  3|\n",
      "|                                        5|  2|\n",
      "|                                        6|  2|\n",
      "|                                        4|  2|\n",
      "|                                        1|  1|\n",
      "|                                        3|  1|\n",
      "|                                        2|  1|\n",
      "+-----------------------------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select distinct MONTH(tpep_pickup_datetime) , QUARTER(tpep_pickup_datetime) as a from parquetTable ORDER BY a DESC\" ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "| diff_minutes| distance|\n",
      "+-------------+---------+\n",
      "| 65.000000000|210240000|\n",
      "| 60.000000000| 57051000|\n",
      "| 60.000000000| 50770000|\n",
      "| 54.000000000| 45799000|\n",
      "| 12.000000000| 43700000|\n",
      "| 29.000000000| 17137000|\n",
      "|364.766666667|   370000|\n",
      "|367.066666667|   275000|\n",
      "|270.600000000|   263000|\n",
      "|271.833333333|   259000|\n",
      "|276.433333333|   242000|\n",
      "|190.316666667|   212000|\n",
      "|215.266666667|   207000|\n",
      "|227.016666667|   207000|\n",
      "|168.283333333|   168000|\n",
      "|168.816666667|   166000|\n",
      "|375.233333333|   164000|\n",
      "|228.800000000|   161000|\n",
      "|226.933333333|   154000|\n",
      "|175.016666667|   151000|\n",
      "+-------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Getting the Difference in Time in SECs and Maximum Distance in Meters and Sorting them Descendingly\n",
    "\n",
    "spark.sql(\"SELECT(EXTRACT (DAY FROM (tpep_dropoff_datetime-tpep_pickup_datetime))*24*60*60+EXTRACT (HOUR FROM (tpep_dropoff_datetime-tpep_pickup_datetime))*60*60+ EXTRACT (MINUTE FROM (tpep_dropoff_datetime-tpep_pickup_datetime))*60+EXTRACT (SECOND FROM (tpep_dropoff_datetime-tpep_pickup_datetime)))/60 as diff_minutes, ABS(trip_distance*1000) as distance FROM parquetTable ORDER BY distance DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: short (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: short (nullable = true)\n",
      " |-- trip_distance: decimal(10,0) (nullable = true)\n",
      " |-- RatecodeID: short (nullable = true)\n",
      " |-- store_and_fwd_flag: decimal(10,0) (nullable = true)\n",
      " |-- PULocationID: short (nullable = true)\n",
      " |-- DOLocationID: short (nullable = true)\n",
      " |-- payment_type: short (nullable = true)\n",
      " |-- fare_amount: decimal(10,0) (nullable = true)\n",
      " |-- extra: decimal(10,0) (nullable = true)\n",
      " |-- mta_tax: decimal(10,0) (nullable = true)\n",
      " |-- tip_amount: decimal(10,0) (nullable = true)\n",
      " |-- tolls_amount: decimal(10,0) (nullable = true)\n",
      " |-- improvement_surcharge: decimal(10,0) (nullable = true)\n",
      " |-- total_amount: decimal(10,0) (nullable = true)\n",
      " |-- congestion_surcharge: decimal(10,0) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|  h|             speed|\n",
      "+---+------------------+\n",
      "|  0|20.000000000833335|\n",
      "|  0|12.943820225184497|\n",
      "|  0|15.525606468333127|\n",
      "|  1|19.793814432173452|\n",
      "|  0|               0.0|\n",
      "|  0|               0.0|\n",
      "|  0|               0.0|\n",
      "| 15|               0.0|\n",
      "| 15|               0.0|\n",
      "|  0| 8.384279475982533|\n",
      "+---+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT EXTRACT(HOUR FROM tpep_dropoff_datetime ) as h, trip_distance *1.6 /((EXTRACT (MINUTE FROM (tpep_dropoff_datetime - tpep_pickup_datetime))/60 + EXTRACT (SECOND FROM (tpep_dropoff_datetime - tpep_pickup_datetime))/3600)) as speed FROM parquetTable; \").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "|  h|AVERAGE_SPEED|\n",
      "+---+-------------+\n",
      "|  5|        34.66|\n",
      "| 16|        31.44|\n",
      "|  4|        31.40|\n",
      "|  8|        30.93|\n",
      "| 17|        30.21|\n",
      "|  6|        29.18|\n",
      "|  0|        28.94|\n",
      "|  3|        28.29|\n",
      "| 15|        27.84|\n",
      "|  1|        27.54|\n",
      "| 18|        26.24|\n",
      "|  2|        26.19|\n",
      "|  7|        26.10|\n",
      "| 23|        25.79|\n",
      "| 19|        24.55|\n",
      "| 22|        24.44|\n",
      "| 21|        23.77|\n",
      "| 20|        23.52|\n",
      "|  9|        23.28|\n",
      "| 14|        22.31|\n",
      "| 10|        21.31|\n",
      "| 13|        21.20|\n",
      "| 11|        20.51|\n",
      "| 12|        20.33|\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT h , CAST(AVG(speed) as NUMERIC(5,2)) as AVERAGE_SPEED from(SELECT EXTRACT(HOUR FROM tpep_dropoff_datetime ) as h, trip_distance *1.6 /((EXTRACT (MINUTE FROM (tpep_dropoff_datetime - tpep_pickup_datetime))/60 + EXTRACT (SECOND FROM (tpep_dropoff_datetime - tpep_pickup_datetime))/3600)) as speed FROM parquetTable ) GROUP BY h ORDER by AVERAGE_SPEED DESC \").show(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "|  h|AVERAGE_SPEED|\n",
      "+---+-------------+\n",
      "|  5|        34.22|\n",
      "|  4|        31.09|\n",
      "|  6|        28.70|\n",
      "|  0|        27.64|\n",
      "|  3|        27.59|\n",
      "|  1|        26.93|\n",
      "|  2|        25.62|\n",
      "| 23|        24.97|\n",
      "| 22|        23.90|\n",
      "|  7|        23.04|\n",
      "| 21|        23.00|\n",
      "| 20|        21.88|\n",
      "|  8|        19.60|\n",
      "| 13|        19.38|\n",
      "| 19|        19.28|\n",
      "| 16|        19.08|\n",
      "| 10|        18.85|\n",
      "| 12|        18.82|\n",
      "| 17|        18.81|\n",
      "| 15|        18.75|\n",
      "| 14|        18.71|\n",
      "| 11|        18.64|\n",
      "|  9|        18.49|\n",
      "| 18|        17.79|\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT h , CAST(AVG(speed) as NUMERIC(5,2)) as AVERAGE_SPEED from(SELECT EXTRACT(HOUR FROM tpep_dropoff_datetime ) as h, trip_distance *1.6 /(( (unix_timestamp(tpep_dropoff_datetime) - unix_timestamp(tpep_pickup_datetime))/3600 )) as speed FROM parquetTable ) GROUP BY h ORDER by AVERAGE_SPEED DESC \").show(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"create temp view new_table1 as SELECT DOLocationID as DROPOff_Location_ID, QUARTER(tpep_dropoff_datetime) as Quarter ,AVG(tip_amount/total_amount)as AVERAGE_TIP_Percentage FROM parquetTable GROUP BY   Quarter,DROPOff_Location_ID order by AVERAGE_TIP_Percentage DESC \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"create temp view new_table4 as select max(AVERAGE_TIP_Percentage) as a ,Quarter from new_table1 GROUP BY new_table1.Quarter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified 1st Query\n",
    "\n",
    "spark.sql(\"SELECT new_table4.a , new_table4.Quarter , new_table1.DROPOff_Location_ID from new_table4 , new_table1 where new_table4.Quarter = new_table1.Quarter and new_table4.a = new_table1.AVERAGE_TIP_Percentage\").show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "+-------------------------------------------------------------------------------+-------+-------------------+\n",
    "|(CAST(a AS DECIMAL(25,15)) * CAST(CAST(100 AS DECIMAL(3,0)) AS DECIMAL(25,15)))|Quarter|DROPOff_Location_ID|\n",
    "+-------------------------------------------------------------------------------+-------+-------------------+\n",
    "|                                                             22.222222222000000|      3|                263|\n",
    "|                                                             20.000000000000000|      4|                232|\n",
    "|                                                             20.000000000000000|      4|                239|\n",
    "|                                                             13.367013360093600|      1|                 40|\n",
    "|                                                             22.727272727000000|      2|                238|\n",
    "+-------------------------------------------------------------------------------+-------+-------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
